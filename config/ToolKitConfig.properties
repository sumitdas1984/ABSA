#xpresso.delimiter=#&#abz#&#
#xpresso.version=4.0.2_2
#
#super_users.file=super_users.txt
#
#domain.names=hospitality,retail,insurance,entertainment,toys,apparel,banking,pharmacy,telecom,automobiles,airlines,airlines_vueling,cigarettes,dining,aoi,environment,protein,wm,city,logistics,government,armamentarium,employment
#subject.mode=true
#review.source=twitter

#custom.aspect.matcher=true
#domainKB.location=domainKB
#domain.non.senti.file=domainNonSentiWords.txt
#domain.config.file=domainConfig.json
#domain.concepts.kb=conceptsKB.txt
#domain.nonsentiment.file=domainNonSentiment.json
resources.dir=resources
resources.static.dir=resources-static
lib.dir=lib
input.dir=input
data.dir=data
models.dir=models
output.dir=output
#mesh.db.location=domainKB/healthCare/conceptsMeSH.txt


#concepts.file.name=domainConcepts.txt
#concepts.file.name=domainConceptsExpanded.txt
#possible.aspects.file.name=possibleAspects.txt
#contextual.sentiment.file.name=contextualSentiment.txt
#concepts.cluster.file.name=conceptClusters.txt

#implicit.concepts.file.name=implicitConcepts.txt

language.names=spanish,english

#weak_verbs.file=weak-verbs.txt
stop_words.file= stopwords_refined.txt
#wordnet.dir=WordNet-3.0
#senti.wordnet.file=SentiWordNet_3.0.0_20130122.txt
#dictionary.file=dict_words.txt

#stanford.use_sr_parser=true

#stanford.sp.depparse=true
#stanford.sp.depparse.model=nndep.spanish9.model.txt-0.1.gz

stanford.annotators=spanish:tokenize,ssplit,pos,ner,parse;english:tokenize,ssplit,pos,lemma,ner,parse,sentiment
#stanford.annotators=spanish:tokenize,ssplit,pos,ner,parse

implicit.aspects.words=implicit-aspects-words.txt
#0=HashMap, 1=GloveAspectSeed, 2=GranularAspectBucketCategory, 3=GloveAspectClusterGranular, 4=GloveAspectHybridClusterGranularAspectSeed, 5=GoogleW2VAspectSeed, 
#6=GoogleW2VHybridClusterGranularAspectSeed, 7=GloveAspectLSH, 8=WordVectorAspectBottomUpMaximalMatch, 9=GloveAspectTopDown, 10=WordVectorBottomUpSemanticSimilarity
#wv.aspects.match=10
#load.wv.categories=false
#load.wv.document=false
#use.lsh=false
#decrease.words=decrease-words.txt
#increase.words=increase-words.txt
#intensifier.words=intensifier-words.txt
negative.words=negative-words.txt
positive.words=positive-words.txt
#uc.negative.words=unconditional-negative-words.txt
#uc.positive.words=unconditional-positive-words.txt
#shifter.words=shifter-words.txt
#NPI.words=NPI-words.txt
#PPI.words=PPI-words.txt
#possession.words=possession-words.txt
#non.possession.words=non-possession-words.txt
#resources.words=resources-words.txt
#consume.words=consume-words.txt
#non_senti.words=non-senti-words.txt
#emoticons.file=emoticons.txt
#idioms.file=idioms.txt
#phrasal.verbs.file=phrasal-verbs.txt
#greetings.salutations.file=greetings-salutations.txt
#pos.tags.file=pos-tags.txt
#replace.patterns.file=preprocess-replace.txt
#suffix.file=suffix-list.txt
#unlisted.entity.file=unlisted_entities.txt
#intent.action.file=intent-action.txt
#intent.object.file=intent-object.txt

#need.words=need-words.txt
#abuse.words=abuse-words.txt
#advocate.words=advocate-words.txt
#suggestion.words=suggestion-words.txt

#ml.senti.model.file=sentiModelFile.model
#ml.stmt.model.file=stmtModelFile.model
#ml.sp.senti.model.file=sentiModelFileSPRF.model
#ml.sp.stmt.model.file=stmtModelFileSPRF.model


#dbAccess.properties=./config/dbAccess.properties
#secondary.concepts.file.name=secondaryDomainConcepts.txt
#use.expanded.domainkb=false

#graphdb.server=http://107.178.217.82:7474
#graphdb.server=http://localhost:7474
#undo.query.file=undo_query.txt
#domain.graph.file=domain_db.txt

#embedded.graphdb=$NEO4J_HOME/data/core.graphdb
#embedded.graphdb=C:\\Users\\Antarip Biswas\\Documents\\Neo4j\\default.graphdb

#use.graphdb=false
#use.embedded.graphdb=false
#upload.static.lexicon=false
#undo.previous.graph=false
#build.domain.graph=false

#emotion.seed.file=emotion_seed.txt
#emotion.kb.file=NRC-emotions-lexicon-filtered.txt

#enable.bing.search=false
#searchengine.max.seed=3

#wv.vector.file=glove_vector.txt

#wv.db.type
#wv.db.types=mongo,memsql
#wv.db.use=0
#wv.db.data=/mnt/pd0/db/data/GoogleNews-vectors-negative300.txt

#bottom-up clusters resource
wv.clusters.file=AllEntitiesClustersBottomUp.txt

#idf.downgrade=true
#batch.run.keyword.significance=false
#trend.batch.run=true
#entity.doc.count.file=doc_entity_trend.txt
#up.factor=1.0
#downfactor.power=2.0
#trend.idf.compute.method=3
#trend.detection.threads=30
#decay.factor=0.0001
#trend.threshold=0.4
#max.trend.topic=100
#trend.type=3
#entity.abundance.type=1
#trend.review.count=10000
#min.trend.topic.count=5

#database credentials
#db.name=dbsingapore
#db.username=root
#db.password=123

#mongo collection
#mongo.wv.load=false
#mongo.wv.read=true
#mongo.host=localhost
#mongo.db=mydb
#mongo.collection=word2vecCollection
#mongo.collection=testCollection

#cache
#use.cache=true
#max.cache.size=1000000

#microtext resources
#microtext.resource.path=twitter
#microtext.resource.files=proper_names,celebs,videogame,mobyplaces,family,female,male
#microtext.tagger.model=model.ritter_ptb_alldata_fixed.20130723
#microtext.tagger.dict=tagdict.txt
#cluster.resource.name=50mpaths2

#input.review.file.name=employment/experisUs.tsv
input.review.file.name=hospitality/olset_data2.txt
#input.review.file.name=mouthshut.tsv
#input.review.file.name=city/small.txt
review.language=EN
review.delimiter=\t
review.field=4
max.review.length=3000
#extracted.entity.file.name=extracted-entity-experis.txt
#extracted.entity.file.name=extracted-entity-1-spanish-vueling
extracted.entity.file.name=extracted-entity-olset

log.max.file.size=50000000
log.max.file.count=50
#Set as OFF/ALL/SEVERE/WARN
logger.level=1
max.engine.threads=100
date.format=yyyyMMdd_HHmmss

#resources used for TMobile POC
#tmobile.conceptKB=./tmobile/tmobileconcepts.txt
